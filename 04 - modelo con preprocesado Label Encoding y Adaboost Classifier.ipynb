{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_11k9PRq1sY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'\n",
        "!chmod 600 ./kaggle.json\n",
        "!kaggle competitions download -c udea-ai-4-eng-20251-pruebas-saber-pro-colombia\n",
        "\n",
        "!unzip udea*.zip > /dev/null\n",
        "!wc *.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWpWIPbsrYm-",
        "outputId": "01949632-47b1-4223-f4b9-2f0935257ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "udea-ai-4-eng-20251-pruebas-saber-pro-colombia.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "replace submission_example.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "   296787    296787   4716673 submission_example.csv\n",
            "   296787   4565553  59185250 test.csv\n",
            "   692501  10666231 143732449 train.csv\n",
            "  1286075  15528571 207634372 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cargar archivos como Dataframes**"
      ],
      "metadata": {
        "id": "b2G9Z1N8raZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "auxiliar_df = train_df.copy()"
      ],
      "metadata": {
        "id": "Wf9DCOolrbRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TODPYp_rccu",
        "outputId": "d8e16b97-ece8-4e02-865e-6cccbf64286f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'PERIODO', 'ESTU_PRGM_ACADEMICO', 'ESTU_PRGM_DEPARTAMENTO',\n",
              "       'ESTU_VALORMATRICULAUNIVERSIDAD', 'ESTU_HORASSEMANATRABAJA',\n",
              "       'FAMI_ESTRATOVIVIENDA', 'FAMI_TIENEINTERNET', 'FAMI_EDUCACIONPADRE',\n",
              "       'FAMI_TIENELAVADORA', 'FAMI_TIENEAUTOMOVIL', 'ESTU_PRIVADO_LIBERTAD',\n",
              "       'ESTU_PAGOMATRICULAPROPIO', 'FAMI_TIENECOMPUTADOR',\n",
              "       'FAMI_TIENEINTERNET.1', 'FAMI_EDUCACIONMADRE', 'RENDIMIENTO_GLOBAL',\n",
              "       'coef_1', 'coef_2', 'coef_3', 'coef_4'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Funciones de Limpieza**"
      ],
      "metadata": {
        "id": "ICsR0rvUre1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Rendimiento Global**"
      ],
      "metadata": {
        "id": "XtEcKYmQrgQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rendimientoglobal(df):\n",
        "  map_dict = {\n",
        "    \"alto\":3,\n",
        "    \"medio-alto\":2,\n",
        "    \"medio-bajo\":1,\n",
        "    \"bajo\": 0\n",
        "  }\n",
        "  df['RENDIMIENTO_GLOBAL'] = df['RENDIMIENTO_GLOBAL'].map(map_dict)"
      ],
      "metadata": {
        "id": "VNHjzaTSreoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Rendimiento Global Reverso**"
      ],
      "metadata": {
        "id": "aOenrqobriHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rendimientoglobalreverse(df):\n",
        "    df['RENDIMIENTO_GLOBAL'] = df['RENDIMIENTO_GLOBAL'].round().astype(int)\n",
        "    map_dict = {\n",
        "        3: \"alto\",\n",
        "        2: \"medio-alto\",\n",
        "        1: \"medio-bajo\",\n",
        "        0: \"bajo\"\n",
        "    }\n",
        "    df['RENDIMIENTO_GLOBAL'] = df['RENDIMIENTO_GLOBAL'].map(map_dict)\n",
        "    return df"
      ],
      "metadata": {
        "id": "y682ERmlri6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Estrato**"
      ],
      "metadata": {
        "id": "DpQXqDrnrn9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estrato(df):\n",
        "    map_dict = {\n",
        "        'Estrato 1': 1,\n",
        "        'Estrato 2': 3,\n",
        "        'Estrato 3': 4,\n",
        "        'Estrato 4': 5,\n",
        "        'Estrato 5': 6,\n",
        "        'Estrato 6': 7,\n",
        "        'Sin Estrato': 2\n",
        "    }\n",
        "\n",
        "    df['FAMI_ESTRATOVIVIENDA'] = df['FAMI_ESTRATOVIVIENDA'].map(map_dict)\n",
        "\n",
        "    # Calcula la moda de manera segura\n",
        "    modas = df['FAMI_ESTRATOVIVIENDA'].mode()\n",
        "    if not modas.empty:\n",
        "        moda = modas.iloc[0]\n",
        "    else:\n",
        "        moda = 0  # valor por defecto si toda la columna es nula\n",
        "\n",
        "    # Reemplaza valores nulos por la moda\n",
        "    def generar_valores(row):\n",
        "        if pd.isna(row):\n",
        "            return moda\n",
        "        return row\n",
        "\n",
        "    df['FAMI_ESTRATOVIVIENDA'] = df['FAMI_ESTRATOVIVIENDA'].apply(generar_valores)\n"
      ],
      "metadata": {
        "id": "y_I4HKF7ro4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Internet**"
      ],
      "metadata": {
        "id": "8kkOLBOxrqyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NUEVO - la probabilidad no es una constante, es el promedio de personas que dijieron que si\n",
        "import random\n",
        "def internet(df):\n",
        "  map_dict = {\n",
        "    'Si': 1,\n",
        "    'No': 0,\n",
        "  }\n",
        "  df['FAMI_TIENEINTERNET'] = df['FAMI_TIENEINTERNET'].map(map_dict)\n",
        "  percent=np.round(df['FAMI_TIENEINTERNET'].mean(),4)\n",
        "\n",
        "  def assign_value(row):\n",
        "    est_value=row['FAMI_ESTRATOVIVIENDA']\n",
        "    if pd.isnull(row['FAMI_TIENEINTERNET']):\n",
        "        if est_value > 2:\n",
        "            return 1\n",
        "        elif np.round(random.random(),4) <= percent:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    else:\n",
        "        return row['FAMI_TIENEINTERNET']\n",
        "\n",
        "  df['FAMI_TIENEINTERNET'] = df.apply(assign_value, axis=1)"
      ],
      "metadata": {
        "id": "Y_O4In1krra2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Matricula Propia**"
      ],
      "metadata": {
        "id": "RJNlP6gErsg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matriculapropia(df):\n",
        "\n",
        "    # Agrupar por departamento y calcular la media y desviación estándar del rendimiento global\n",
        "    res_mean = auxiliar_df.groupby('ESTU_PAGOMATRICULAPROPIO')[\"RENDIMIENTO_GLOBAL\"].mean()\n",
        "    res_std = auxiliar_df.groupby('ESTU_PAGOMATRICULAPROPIO')[\"RENDIMIENTO_GLOBAL\"].std()\n",
        "\n",
        "    # Mapear los resultados en el DataFrame\n",
        "    df['ESTU_PAGOMATRICULAPROPIO'] = df['ESTU_PAGOMATRICULAPROPIO'].map(res_mean)\n",
        "\n",
        "    # Función para generar valores aleatorios con la misma media y desviación estándar\n",
        "    def generar_valores_normales(row):\n",
        "        if pd.isna(row):  # Si el valor es nulo\n",
        "            mean = res_mean.mean()\n",
        "            std = res_std.mean()\n",
        "            return np.random.normal(mean, std)\n",
        "        return row\n",
        "\n",
        "    # Aplicar la función para sustituir los valores nulos con una distribución normal equivalente\n",
        "    df['ESTU_PAGOMATRICULAPROPIO'] = df['ESTU_PAGOMATRICULAPROPIO'].apply(generar_valores_normales)\n"
      ],
      "metadata": {
        "id": "fN2OexnFrtI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Horas que Trabaja**"
      ],
      "metadata": {
        "id": "w3l0xbZxrvle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def horassemanatrabaja(df):\n",
        "    map_dict = {\n",
        "        '0': 5,\n",
        "        'Entre 11 y 20 horas': 3,\n",
        "        'Entre 21 y 30 horas': 2,\n",
        "        'Menos de 10 horas': 4,\n",
        "        'Más de 30 horas': 1\n",
        "    }\n",
        "\n",
        "    df['ESTU_HORASSEMANATRABAJA'] = df['ESTU_HORASSEMANATRABAJA'].map(map_dict)\n",
        "\n",
        "    # calcula la moda de forma segura\n",
        "    modas = df['ESTU_HORASSEMANATRABAJA'].mode()\n",
        "    if not modas.empty:\n",
        "        moda = modas.iloc[0]\n",
        "    else:\n",
        "        moda = 0  # o el valor por defecto que prefieras\n",
        "\n",
        "    # rellena los valores nulos con la moda\n",
        "    df['ESTU_HORASSEMANATRABAJA'] = df['ESTU_HORASSEMANATRABAJA'].fillna(moda)"
      ],
      "metadata": {
        "id": "jnRAFKK0rwce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Valor de la Matricula**"
      ],
      "metadata": {
        "id": "OPjKQ79qrx4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def valormatriculauniversidad(df):\n",
        "    map_dict = {\n",
        "        'Entre 1 millón y menos de 2.5 millones': 1,\n",
        "        'Entre 2.5 millones y menos de 4 millones': 2,\n",
        "        'Entre 4 millones y menos de 5.5 millones': 6,\n",
        "        'Entre 5.5 millones y menos de 7 millones': 7,\n",
        "        'Entre 500 mil y menos de 1 millón': 3,\n",
        "        'Menos de 500 mil': 5,\n",
        "        'Más de 7 millones': 8,\n",
        "        'No pagó matrícula': 4\n",
        "    }\n",
        "\n",
        "    df['ESTU_VALORMATRICULAUNIVERSIDAD'] = df['ESTU_VALORMATRICULAUNIVERSIDAD'].map(map_dict)\n",
        "\n",
        "    # calcula la moda de forma segura\n",
        "    modas = df['ESTU_VALORMATRICULAUNIVERSIDAD'].mode()\n",
        "    if not modas.empty:\n",
        "        moda = modas.iloc[0]\n",
        "    else:\n",
        "        moda = 0  # valor por defecto si no hay datos válidos\n",
        "\n",
        "    # reemplaza nulos con la moda\n",
        "    df['ESTU_VALORMATRICULAUNIVERSIDAD'] = df['ESTU_VALORMATRICULAUNIVERSIDAD'].fillna(moda)"
      ],
      "metadata": {
        "id": "hRcJhOxxryTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Educación de Padre**"
      ],
      "metadata": {
        "id": "9bMJm7f2r0QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def educacionpadre(df):\n",
        "    map_dict = {\n",
        "        'Educación profesional completa': 11,\n",
        "        'Educación profesional incompleta': 10,\n",
        "        'Ninguno': 1,\n",
        "        'No Aplica': 7,\n",
        "        'No sabe': 9,\n",
        "        'Postgrado': 12,\n",
        "        'Primaria completa': 3,\n",
        "        'Primaria incompleta': 2,\n",
        "        'Secundaria (Bachillerato) completa': 6,\n",
        "        'Secundaria (Bachillerato) incompleta': 4,\n",
        "        'Técnica o tecnológica completa': 8,\n",
        "        'Técnica o tecnológica incompleta': 5\n",
        "    }\n",
        "\n",
        "    df['FAMI_EDUCACIONPADRE'] = df['FAMI_EDUCACIONPADRE'].map(map_dict)\n",
        "\n",
        "    modas = df['FAMI_EDUCACIONPADRE'].mode()\n",
        "    moda = modas.iloc[0] if not modas.empty else 0\n",
        "\n",
        "    df['FAMI_EDUCACIONPADRE'] = df['FAMI_EDUCACIONPADRE'].fillna(moda)\n"
      ],
      "metadata": {
        "id": "JYxoeGcSr1Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Educación de Madre**"
      ],
      "metadata": {
        "id": "2O7MA04Dr22W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def educacionmadre(df):\n",
        "    map_dict = {\n",
        "        'Educación profesional completa': 11,\n",
        "        'Educación profesional incompleta': 10,\n",
        "        'Ninguno': 1,\n",
        "        'No Aplica': 4,\n",
        "        'No sabe': 6,\n",
        "        'Postgrado': 12,\n",
        "        'Primaria completa': 3,\n",
        "        'Primaria incompleta': 2,\n",
        "        'Secundaria (Bachillerato) completa': 7,\n",
        "        'Secundaria (Bachillerato) incompleta': 5,\n",
        "        'Técnica o tecnológica completa': 9,\n",
        "        'Técnica o tecnológica incompleta': 8\n",
        "    }\n",
        "\n",
        "    df['FAMI_EDUCACIONMADRE'] = df['FAMI_EDUCACIONMADRE'].map(map_dict)\n",
        "\n",
        "    # calcula la moda de forma segura\n",
        "    modas = df['FAMI_EDUCACIONMADRE'].mode()\n",
        "    if not modas.empty:\n",
        "        moda = modas.iloc[0]\n",
        "    else:\n",
        "        moda = 0  # o el valor que prefieras por defecto\n",
        "\n",
        "    # rellena nulos con la moda\n",
        "    df['FAMI_EDUCACIONMADRE'] = df['FAMI_EDUCACIONMADRE'].fillna(moda)"
      ],
      "metadata": {
        "id": "3yE-udxKr3v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Periodo**"
      ],
      "metadata": {
        "id": "XQN4PI6Xr4xG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def periodo(df):\n",
        "    df['PERIODO'] = df['PERIODO'].astype(str)\n",
        "\n",
        "    map_dict = {\n",
        "        \"20183\": 5,\n",
        "        \"20184\": 1,\n",
        "        \"20194\": 9,\n",
        "        \"20195\": 3,\n",
        "        \"20196\": 4,\n",
        "        \"20202\": 8,\n",
        "        \"20203\": 6,\n",
        "        \"20212\": 2,\n",
        "        \"20213\": 7\n",
        "    }\n",
        "\n",
        "    df['PERIODO'] = df['PERIODO'].map(map_dict)\n",
        "\n",
        "    modas = df['PERIODO'].mode()\n",
        "    if not modas.empty:\n",
        "        moda = modas.iloc[0]\n",
        "    else:\n",
        "        moda = 0  # o el valor que prefieras como predeterminado\n",
        "\n",
        "    df['PERIODO'] = df['PERIODO'].fillna(moda)"
      ],
      "metadata": {
        "id": "6gVKQ0wVr5ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Departamento**"
      ],
      "metadata": {
        "id": "WPUlh9VIr8_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def departamento(df):\n",
        "\n",
        "    # Agrupar por departamento y calcular la media y desviación estándar del rendimiento global\n",
        "    res_mean = auxiliar_df.groupby('ESTU_PRGM_DEPARTAMENTO')[\"RENDIMIENTO_GLOBAL\"].mean()\n",
        "\n",
        "    # Mapear los resultados en el DataFrame\n",
        "    df['ESTU_PRGM_DEPARTAMENTO'] = df['ESTU_PRGM_DEPARTAMENTO'].map(res_mean)\n",
        "\n",
        "    # Función para generar valores aleatorios con la misma media y desviación estándar\n",
        "    def generar_valores_normales(row):\n",
        "        if pd.isna(row):  # Si el valor es nulo\n",
        "            mean = auxiliar_df['RENDIMIENTO_GLOBAL'].mean()\n",
        "            return mean\n",
        "        return row\n",
        "\n",
        "    # Aplicar la función para sustituir los valores nulos con una distribución normal equivalente\n",
        "    df['ESTU_PRGM_DEPARTAMENTO'] = df['ESTU_PRGM_DEPARTAMENTO'].apply(generar_valores_normales)\n"
      ],
      "metadata": {
        "id": "Hks0plQAr_ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Programa Acádemico**"
      ],
      "metadata": {
        "id": "LRDcV6wcsBGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def programaacademico(df):\n",
        "\n",
        "    # Agrupar por departamento y calcular la media y desviación estándar del rendimiento global\n",
        "    res_mean = auxiliar_df.groupby('ESTU_PRGM_ACADEMICO')[\"RENDIMIENTO_GLOBAL\"].mean()\n",
        "\n",
        "    # Mapear los resultados en el DataFrame\n",
        "    df['ESTU_PRGM_ACADEMICO'] = df['ESTU_PRGM_ACADEMICO'].map(res_mean)\n",
        "\n",
        "    # Función para generar valores aleatorios con la misma media y desviación estándar\n",
        "    def generar_valores_normales(row):\n",
        "        if pd.isna(row):  # Si el valor es nulo\n",
        "            mean = auxiliar_df['RENDIMIENTO_GLOBAL'].mean()\n",
        "            return mean\n",
        "        return row\n",
        "\n",
        "    # Aplicar la función para sustituir los valores nulos con una distribución normal equivalente\n",
        "    df['ESTU_PRGM_ACADEMICO'] = df['ESTU_PRGM_ACADEMICO'].apply(generar_valores_normales)\n"
      ],
      "metadata": {
        "id": "_lKajwvQsB73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Columnas binarias**"
      ],
      "metadata": {
        "id": "pQYCABM5sDL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def columnas_binarias(df):\n",
        "    \"\"\"Convierte las columnas binarias 'Si'/'No' a 1/0\"\"\"\n",
        "    binarias = [\n",
        "        'FAMI_TIENELAVADORA',\n",
        "        'FAMI_TIENEAUTOMOVIL',\n",
        "        'ESTU_PRIVADO_LIBERTAD',\n",
        "        'FAMI_TIENECOMPUTADOR',\n",
        "        'FAMI_TIENEINTERNET.1'\n",
        "    ]\n",
        "    for col in binarias:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].map({'Si': 1, 'No': 0})\n",
        "            df[col] = df[col].fillna(0)  # opcional: llena nulos con 0"
      ],
      "metadata": {
        "id": "KuCI9EfYsD8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Limpieza Total**"
      ],
      "metadata": {
        "id": "G6EQivddsFhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def limpiar_df(df, predict=False, test=False):\n",
        "  if not predict:\n",
        "    if not test:\n",
        "      rendimientoglobal(df)\n",
        "    estrato(df)\n",
        "    internet(df)\n",
        "    matriculapropia(df)\n",
        "    valormatriculauniversidad(df)\n",
        "    educacionpadre(df)\n",
        "    educacionmadre(df)\n",
        "    horassemanatrabaja(df)\n",
        "    departamento(df)\n",
        "    programaacademico(df)\n",
        "    periodo(df)\n",
        "    columnas_binarias(df)\n",
        "    return df\n",
        "  elif predict:\n",
        "    rendimientoglobal(df)"
      ],
      "metadata": {
        "id": "JlPIhvJAsGYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "limpiar_df(auxiliar_df, predict=True)\n",
        "train_df2 = limpiar_df(train_df)\n",
        "test_df2 = limpiar_df(test_df, test=True)"
      ],
      "metadata": {
        "id": "brMksydWsHef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adaboost Classifier**"
      ],
      "metadata": {
        "id": "jC2-lfHFsI8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "df = train_df.copy()\n",
        "\n",
        "# Separar características (X) y la variable objetivo (y)\n",
        "X = df.drop(columns=[\"RENDIMIENTO_GLOBAL\",\"ID\"], axis=1)\n",
        "y = df[\"RENDIMIENTO_GLOBAL\"]\n",
        "# Supongamos que ya tienes tus datos preparados: X y y\n",
        "# X es tu conjunto de características y y son las etiquetas\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Rellenar nulos con 0\n",
        "X_train = X_train.fillna(0)\n",
        "X_test = X_test.fillna(0)\n",
        "\n",
        "# Inicializar el modelo de AdaBoost\n",
        "# Puedes usar un árbol de decisión como modelo base\n",
        "base_estimator = DecisionTreeClassifier(max_depth=5)  # Un árbol poco profundo\n",
        "ada_classifier = AdaBoostClassifier(estimator=base_estimator,\n",
        "                                     n_estimators=50,  # Número de modelos débiles\n",
        "                                     learning_rate=0.3,  # Tasa de aprendizaje\n",
        "                                     random_state=73)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "# Entrenar el modelo\n",
        "ada_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Hacer predicciones\n",
        "y_pred = ada_classifier.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Precisión: {accuracy}')\n",
        "\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(f\"Entrenamiento completado en {end - start:.2f} segundos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd0wHJ1_sJq2",
        "outputId": "0a8ac457-0b8a-4955-814c-1e7863614066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión: 0.4180361010830325\n",
            "Entrenamiento completado en 157.20 segundos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear copia limpia del test\n",
        "df_test_est = test_df2.copy()\n",
        "\n",
        "# Eliminar columnas que no estaban en el entrenamiento\n",
        "df_test_est = df_test_est.drop(columns=[\"ID\"], errors='ignore')  # Ignora si no existe\n",
        "df_test_est = df_test_est.drop(columns=[\"Unnamed: 0\"], errors='ignore')\n",
        "\n",
        "# Realizar predicciones\n",
        "predicciones = ada_classifier.predict(df_test_est)"
      ],
      "metadata": {
        "id": "NtY1yPQtvnQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear DataFrame con ID y predicciones\n",
        "id_column = \"ID\" if \"ID\" in test_df.columns else test_df.index\n",
        "y = pd.DataFrame({ \"ID\": test_df[id_column], \"RENDIMIENTO_GLOBAL\": predicciones })\n",
        "\n",
        "# Función para revertir el rendimiento global a etiquetas originales\n",
        "def rendimientoglobalreverse(df):\n",
        "    df[\"RENDIMIENTO_GLOBAL\"] = df[\"RENDIMIENTO_GLOBAL\"].round().astype(int)\n",
        "    map_dict = {3: \"alto\", 2: \"medio-alto\", 1: \"medio-bajo\", 0: \"bajo\"}\n",
        "    df[\"RENDIMIENTO_GLOBAL\"] = df[\"RENDIMIENTO_GLOBAL\"].map(map_dict)\n",
        "    return df\n",
        "\n",
        "# Aplicar reversión y guardar CSV\n",
        "y = rendimientoglobalreverse(y)\n",
        "y.to_csv(\"submission.csv\", index=False)\n",
        "print(\"✅ Archivo 'submission.csv' guardado correctamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVmnNjONuVh_",
        "outputId": "131aa4bd-e669-4d74-c3f5-1ce7f6daf8f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Archivo 'submission.csv' guardado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predicción Kaggle**"
      ],
      "metadata": {
        "id": "AVWS-6PtsLW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c udea-ai-4-eng-20251-pruebas-saber-pro-colombia -f submission.csv -m \"Intento con AdaBoost de Camilo\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpZ53OYYsea_",
        "outputId": "a0006b1e-ac41-4d64-934d-e71948c8c8ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 4.10M/4.10M [00:00<00:00, 9.74MB/s]\n",
            "Successfully submitted to UDEA/ai4eng 20251 - Pruebas Saber Pro Colombia"
          ]
        }
      ]
    }
  ]
}